{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "earned-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "integrated-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters = 64, kernel_size = (3, 3), strides = 1, padding = 'same', input_shape = (224, 224, 3), activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 64, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 128, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 128, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 512, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 512, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 512, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 512, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 512, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    Conv2D(filters = 512, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu', kernel_regularizer=l2(0.0005)),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1000, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "quiet-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_162 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_164 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_165 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_168 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_169 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_170 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_171 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_173 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "endless-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "indie-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Add, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# CIFAR-10 데이터셋 로드\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# 데이터 정규화\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# 레이블을 원-핫 인코딩으로 변환\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "\n",
    "# ResNet-34 모델 정의\n",
    "def resnet_34(input_shape=(32, 32, 3), num_classes=10):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    # ============================= conv1 =============================\n",
    "    x1 = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2), strides=2)(x1)\n",
    "    shortcut = x1\n",
    "\n",
    "    # ============================= conv2_x =============================\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # ============================= conv3_x =============================\n",
    "    shortcut = Conv2D(128, (1, 1), strides=(2, 2), padding='same')(shortcut)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # ============================= conv4_x =============================\n",
    "    shortcut = Conv2D(256, (1, 1), strides=(2, 2), padding='same')(shortcut)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # ============================= conv5_x =============================\n",
    "    shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='same')(shortcut)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    shortcut = x\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "annual-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-34 모델 생성\n",
    "model = resnet_34(input_shape=(32, 32, 3), num_classes=10)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "pediatric-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 16, 16, 64)   9472        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 16, 16, 64)   256         conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 16, 16, 64)   0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D) (None, 8, 8, 64)     0           activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 8, 8, 64)     36928       max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 8, 8, 64)     256         conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 8, 8, 64)     0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 8, 8, 64)     36928       activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 8, 8, 64)     256         conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_170 (Add)                   (None, 8, 8, 64)     0           batch_normalization_392[0][0]    \n",
      "                                                                 max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 8, 8, 64)     0           add_170[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 8, 8, 64)     36928       activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 8, 8, 64)     256         conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 8, 8, 64)     0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 8, 8, 64)     36928       activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 8, 8, 64)     256         conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_171 (Add)                   (None, 8, 8, 64)     0           batch_normalization_394[0][0]    \n",
      "                                                                 add_170[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 8, 8, 64)     0           add_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 8, 8, 64)     36928       activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 8, 8, 64)     256         conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 8, 8, 64)     0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 8, 8, 64)     36928       activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 8, 8, 64)     256         conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_172 (Add)                   (None, 8, 8, 64)     0           batch_normalization_396[0][0]    \n",
      "                                                                 add_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 8, 8, 64)     0           add_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 4, 4, 128)    73856       activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 4, 4, 128)    512         conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 4, 4, 128)    0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 4, 4, 128)    147584      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 4, 4, 128)    8320        add_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 4, 4, 128)    512         conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 4, 4, 128)    512         conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_173 (Add)                   (None, 4, 4, 128)    0           batch_normalization_399[0][0]    \n",
      "                                                                 batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 4, 4, 128)    0           add_173[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 4, 4, 128)    147584      activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 4, 4, 128)    512         conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 4, 4, 128)    0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 4, 4, 128)    147584      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 4, 4, 128)    512         conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_174 (Add)                   (None, 4, 4, 128)    0           batch_normalization_401[0][0]    \n",
      "                                                                 add_173[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 4, 4, 128)    0           add_174[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 4, 4, 128)    147584      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 4, 4, 128)    512         conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 4, 4, 128)    0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 4, 4, 128)    147584      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 4, 4, 128)    512         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_175 (Add)                   (None, 4, 4, 128)    0           batch_normalization_403[0][0]    \n",
      "                                                                 add_174[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 4, 4, 128)    0           add_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 4, 4, 128)    147584      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 4, 4, 128)    512         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 4, 4, 128)    0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 4, 4, 128)    147584      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 4, 4, 128)    512         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_176 (Add)                   (None, 4, 4, 128)    0           batch_normalization_405[0][0]    \n",
      "                                                                 add_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 4, 4, 128)    0           add_176[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 2, 2, 256)    295168      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 2, 2, 256)    1024        conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 2, 2, 256)    0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 2, 2, 256)    590080      activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 2, 2, 256)    33024       add_176[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 2, 2, 256)    1024        conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 2, 2, 256)    1024        conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_177 (Add)                   (None, 2, 2, 256)    0           batch_normalization_408[0][0]    \n",
      "                                                                 batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 2, 2, 256)    0           add_177[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 2, 2, 256)    590080      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 2, 2, 256)    1024        conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 2, 2, 256)    0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 2, 2, 256)    590080      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 2, 2, 256)    1024        conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_178 (Add)                   (None, 2, 2, 256)    0           batch_normalization_410[0][0]    \n",
      "                                                                 add_177[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 2, 2, 256)    0           add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 2, 2, 256)    590080      activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 2, 2, 256)    1024        conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 2, 2, 256)    0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 2, 2, 256)    590080      activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 2, 2, 256)    1024        conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_179 (Add)                   (None, 2, 2, 256)    0           batch_normalization_412[0][0]    \n",
      "                                                                 add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 2, 2, 256)    0           add_179[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 2, 2, 256)    590080      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 2, 2, 256)    1024        conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 2, 2, 256)    0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 2, 2, 256)    590080      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 2, 2, 256)    1024        conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_180 (Add)                   (None, 2, 2, 256)    0           batch_normalization_414[0][0]    \n",
      "                                                                 add_179[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 2, 2, 256)    0           add_180[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 2, 2, 256)    590080      activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 2, 2, 256)    1024        conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 2, 2, 256)    0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 2, 2, 256)    590080      activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 2, 2, 256)    1024        conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_181 (Add)                   (None, 2, 2, 256)    0           batch_normalization_416[0][0]    \n",
      "                                                                 add_180[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 2, 2, 256)    0           add_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 2, 2, 256)    590080      activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 2, 2, 256)    1024        conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 2, 2, 256)    0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 2, 2, 256)    590080      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 2, 2, 256)    1024        conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_182 (Add)                   (None, 2, 2, 256)    0           batch_normalization_418[0][0]    \n",
      "                                                                 add_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 2, 2, 256)    0           add_182[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 1, 1, 512)    1180160     activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 1, 1, 512)    2048        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 1, 1, 512)    0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 1, 1, 512)    2359808     activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 1, 1, 512)    131584      add_182[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 1, 1, 512)    2048        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 1, 1, 512)    2048        conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_183 (Add)                   (None, 1, 1, 512)    0           batch_normalization_421[0][0]    \n",
      "                                                                 batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 1, 1, 512)    0           add_183[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 1, 1, 512)    2359808     activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 1, 1, 512)    2048        conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 1, 1, 512)    0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 1, 1, 512)    2359808     activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 1, 1, 512)    2048        conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_184 (Add)                   (None, 1, 1, 512)    0           batch_normalization_423[0][0]    \n",
      "                                                                 add_183[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 1, 1, 512)    0           add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 1, 1, 512)    2359808     activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 1, 1, 512)    2048        conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 1, 1, 512)    0           batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 1, 1, 512)    2359808     activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 1, 1, 512)    2048        conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_185 (Add)                   (None, 1, 1, 512)    0           batch_normalization_425[0][0]    \n",
      "                                                                 add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 1, 1, 512)    0           add_185[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 512)          0           activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           5130        global_average_pooling2d_6[0][0] \n",
      "==================================================================================================\n",
      "Total params: 21,315,338\n",
      "Trainable params: 21,298,314\n",
      "Non-trainable params: 17,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "charitable-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.0797 - accuracy: 0.9721 - val_loss: 1.2430 - val_accuracy: 0.7430\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.0604 - accuracy: 0.9793 - val_loss: 1.2703 - val_accuracy: 0.7581\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0777 - accuracy: 0.9743 - val_loss: 1.4503 - val_accuracy: 0.7276\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0807 - accuracy: 0.9736 - val_loss: 1.1466 - val_accuracy: 0.7581\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0479 - accuracy: 0.9838 - val_loss: 1.4132 - val_accuracy: 0.7461\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0500 - accuracy: 0.9840 - val_loss: 1.5914 - val_accuracy: 0.7166\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0543 - accuracy: 0.9821 - val_loss: 2.3135 - val_accuracy: 0.6518\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 1.7106 - val_accuracy: 0.7127\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0471 - accuracy: 0.9846 - val_loss: 1.4813 - val_accuracy: 0.7214\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 2.0678 - val_accuracy: 0.6645\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0469 - accuracy: 0.9847 - val_loss: 1.3990 - val_accuracy: 0.7535\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 1.5062 - val_accuracy: 0.7263\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0396 - accuracy: 0.9862 - val_loss: 1.4946 - val_accuracy: 0.7344\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 1.2057 - val_accuracy: 0.7678\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 1.4410 - val_accuracy: 0.7595\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0388 - accuracy: 0.9868 - val_loss: 1.7020 - val_accuracy: 0.7171\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 1.5050 - val_accuracy: 0.7351\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 1.4438 - val_accuracy: 0.7531\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0544 - accuracy: 0.9824 - val_loss: 1.3439 - val_accuracy: 0.7599\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 1.3751 - val_accuracy: 0.7605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3d42253a0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(train_images, train_labels, epochs=20, validation_data=(test_images, test_labels), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "employed-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "base_model = keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32, 32, 3))\n",
    "\n",
    "base_model.trainable = True # 사전 훈련된 모델의 가중치를 고정할건지 말건지\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation = 'relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fatal-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 196s 146ms/step - loss: 1.7459 - accuracy: 0.4730 - val_loss: 2.9194 - val_accuracy: 0.2536\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.0835 - accuracy: 0.6389 - val_loss: 1.1840 - val_accuracy: 0.6175\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9965 - accuracy: 0.6716 - val_loss: 1.3874 - val_accuracy: 0.5593\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9227 - accuracy: 0.6943 - val_loss: 0.9453 - val_accuracy: 0.6814\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 0.6743 - accuracy: 0.7789 - val_loss: 2.5295 - val_accuracy: 0.2131\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.9956 - accuracy: 0.6585 - val_loss: 0.9089 - val_accuracy: 0.7003\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.6394 - accuracy: 0.7896 - val_loss: 0.8364 - val_accuracy: 0.7300\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.5253 - accuracy: 0.8256 - val_loss: 0.8544 - val_accuracy: 0.7373\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.5104 - accuracy: 0.8309 - val_loss: 0.8773 - val_accuracy: 0.7286\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.4001 - accuracy: 0.8660 - val_loss: 1.1505 - val_accuracy: 0.6371\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs = 10, validation_data = (test_images, test_labels), batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-netscape",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
